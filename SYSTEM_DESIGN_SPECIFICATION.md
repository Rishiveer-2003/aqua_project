# Project AQUA: System Design Specification
**For Visual Diagram Creation**

This document provides a detailed textual description of the system architecture, components, data flows, and interactions. Use this specification to create visual system design diagrams.

---

## 1. HIGH-LEVEL SYSTEM ARCHITECTURE

### 1.1 Three-Tier Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRESENTATION LAYER                        â”‚
â”‚              (Streamlit Web Application)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     APPLICATION LAYER                        â”‚
â”‚        (Business Logic, ML Inference, Data Processing)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DATA LAYER                             â”‚
â”‚      (Models, Datasets, APIs, Cache)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tier Descriptions:**
- **Presentation Layer:** User interface, visualization, user interactions
- **Application Layer:** ML model loading, prediction logic, feature engineering, SHAP explainability
- **Data Layer:** Stored models (.pkl files), CSV dataset, external weather APIs, caching mechanisms

---

## 2. COMPONENT BREAKDOWN

### 2.1 Presentation Layer Components

**A. Streamlit Web Application**
```
Main App (app.py - Homepage)
â”œâ”€â”€ Sidebar Navigation
â”‚   â”œâ”€â”€ Page Selector
â”‚   â””â”€â”€ Settings/Filters
â”œâ”€â”€ India Live Flood Forecast Module
â”‚   â”œâ”€â”€ City Search Dropdown (32 cities)
â”‚   â”œâ”€â”€ Model Selection (Ensemble/Individual)
â”‚   â”œâ”€â”€ Map Layer Toggle (Heatmap/Hexagon/Scatter)
â”‚   â”œâ”€â”€ Pydeck 3D Map Visualization
â”‚   â””â”€â”€ Risk Prediction Display
â””â”€â”€ Real-time Weather Integration

Page 1: Historical Event Analyzer (pages/1_ğŸ•°ï¸_Historical_Event_Analyzer.py)
â”œâ”€â”€ City Selector
â”œâ”€â”€ Date Picker (1940 - present, with 5-day delay)
â”œâ”€â”€ Model Selection
â”œâ”€â”€ Historical Rainfall Display
â””â”€â”€ Risk Conclusion (LOW/MODERATE/HIGH)

Page 2: Model Performance Dashboard (pages/2_ğŸ“Š_Model_Performance.py)
â”œâ”€â”€ Performance Metrics Table (RMSE, RÂ²)
â”œâ”€â”€ Model Comparison Charts
â”œâ”€â”€ SHAP Global Feature Importance Plots
â””â”€â”€ Model Selection Interface

Page 3: Interactive Risk Calculator (pages/3_ğŸ”¬_Risk_Calculator.py)
â”œâ”€â”€ 20 Feature Sliders (Sidebar)
â”œâ”€â”€ Model Selection (Ensemble/Single)
â”œâ”€â”€ Real-time Prediction Display
â”œâ”€â”€ SHAP Force Plot (Explainability)
â””â”€â”€ Optional Live Weather Helper
```

### 2.2 Application Layer Components

**B. ML Inference Engine**
```
Model Manager
â”œâ”€â”€ Model Loader (joblib deserialization)
â”œâ”€â”€ Feature Alignment (feature_columns.json)
â”œâ”€â”€ Prediction Router
â”‚   â”œâ”€â”€ Ensemble Mode (average of 5 models)
â”‚   â””â”€â”€ Single Model Mode (user-selected)
â”œâ”€â”€ Classifier/Regressor Handler
â””â”€â”€ Output Formatter (probability scaling)

Feature Engineering Module
â”œâ”€â”€ Rainfall-to-Intensity Mapper (mm â†’ MonsoonIntensity [0-16])
â”œâ”€â”€ Grid-based Feature Generator (intra-city variation)
â”œâ”€â”€ Live Weather Feature Extractor
â””â”€â”€ User Input Feature Validator
```

**C. Explainability Module (SHAP)**
```
SHAP Engine
â”œâ”€â”€ TreeExplainer Initialization (gradient boosting models)
â”œâ”€â”€ Global Feature Importance Calculator
â”‚   â”œâ”€â”€ SHAP Summary Plots
â”‚   â””â”€â”€ Feature Ranking
â”œâ”€â”€ Local Feature Importance Calculator
â”‚   â””â”€â”€ SHAP Force Plots (single prediction)
â””â”€â”€ Visualization Generator (matplotlib)
```

**D. Data Processing Module**
```
Preprocessing Pipeline (train_models.py)
â”œâ”€â”€ Data Loader (CSV reader)
â”œâ”€â”€ Missing Value Imputer
â”‚   â”œâ”€â”€ Numeric: Median fill
â”‚   â””â”€â”€ Categorical: Mode fill
â”œâ”€â”€ Feature Validator (20 features required)
â”œâ”€â”€ Train-Test Splitter (80/20, stratified, seed=42)
â””â”€â”€ Feature Saver (feature_columns.json)
```

### 2.3 Data Layer Components

**E. Persistent Storage**
```
Local File System
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ lgbm_model.pkl (LightGBM serialized model)
â”‚   â”œâ”€â”€ rf_model.pkl (Random Forest serialized model)
â”‚   â”œâ”€â”€ xgboost_model.pkl (XGBoost serialized model)
â”‚   â”œâ”€â”€ svr_model.pkl (SVR serialized model)
â”‚   â””â”€â”€ knn_model.pkl (KNN serialized model)
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ flood.csv (50,001 samples, 21 columns)
â”‚   â””â”€â”€ feature_columns.json (feature ordering schema)
â””â”€â”€ Cache/
    â””â”€â”€ .cache/requests_cache.sqlite (HTTP cache)
```

**F. External APIs**
```
Open-Meteo Forecast API
â”œâ”€â”€ Endpoint: https://api.open-meteo.com/v1/forecast
â”œâ”€â”€ Parameters: latitude, longitude, daily=precipitation_sum
â”œâ”€â”€ Response: Tomorrow's rainfall in mm
â””â”€â”€ Caching: requests-cache with retry logic

Open-Meteo Archive API
â”œâ”€â”€ Endpoint: https://archive-api.open-meteo.com/v1/archive
â”œâ”€â”€ Parameters: latitude, longitude, start_date, end_date, daily=precipitation_sum
â”œâ”€â”€ Response: Historical daily rainfall (1940-present)
â””â”€â”€ Data Delay: 5-day processing delay constraint
```

**G. In-Memory Cache**
```
Streamlit Cache
â”œâ”€â”€ @st.cache_resource
â”‚   â””â”€â”€ Model Loading (lgbm_model, rf_model, xgb_model, svr_model, knn_model)
â””â”€â”€ @st.cache_data
    â”œâ”€â”€ Rainfall Forecast Fetching (TTL-based)
    â””â”€â”€ Historical Rainfall Fetching (TTL-based)
```

---

## 3. DATA FLOW DIAGRAMS (Textual Descriptions)

### 3.1 Training Pipeline Data Flow

```
[flood.csv] 
    â†“ (load 50,001 samples)
[Data Loader]
    â†“ (validate 21 columns)
[Preprocessing Module]
    â†“ (median/mode imputation)
[Clean Dataset (no nulls)]
    â†“ (extract 20 features + 1 target)
[Feature Extractor]
    â†“ (save feature order)
[feature_columns.json]
    â†“ (split 80/20, stratified)
[Train/Test Split]
    â”œâ”€â†’ [Training Set: 40,000 samples] â”€â”€â”
    â””â”€â†’ [Testing Set: 10,000 samples]    â”‚
                                          â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       5 Model Training (Parallel)          â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ LGBMRegressor(random_state=42)             â”‚
                    â”‚ RandomForestRegressor(n_estimators=50)     â”‚
                    â”‚ XGBRegressor(n_estimators=200, ...)        â”‚
                    â”‚ SVR(kernel='rbf', C=1.0, epsilon=0.1)      â”‚
                    â”‚ KNeighborsRegressor(n_neighbors=7)         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         Model Evaluation                   â”‚
                    â”‚  (RMSE, RÂ² on 10,000 test samples)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Model Serialization (joblib)           â”‚
                    â”‚    compress=9 for GitHub deployment       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“
            [5 .pkl files saved to disk] + [Performance Metrics Logged]
```

### 3.2 Live Forecast Data Flow (Homepage)

```
[User Opens Homepage]
    â†“
[Streamlit UI Loads]
    â†“
[Load 5 Models from Cache (@st.cache_resource)]
    â†“
[User Selects City from Dropdown]
    â†“
[Retrieve City Profile (lat, lon, baseline risk factors)]
    â†“
[Call Open-Meteo Forecast API (lat, lon)]
    â†“ (returns tomorrow's rainfall_mm)
[Rainfall Fetched (@st.cache_data, 1-hour TTL)]
    â†“
[Map rainfall_mm to MonsoonIntensity [0-16]]
    â†“
[Generate 100-point Grid Around City Center]
    â†“ (add intra-city variation)
[Create Feature Matrix (100 rows Ã— 20 features)]
    â†“
[User Selects Model (Ensemble or Single)]
    â†“
    â”œâ”€â†’ [Ensemble Mode] â”€â”€â†’ [Predict with all 5 models] â”€â”€â†’ [Average predictions]
    â””â”€â†’ [Single Model Mode] â”€â”€â†’ [Predict with selected model]
    â†“
[100 Flood Probabilities (0-1)]
    â†“
[User Selects Map Layer (Heatmap/Hexagon/Scatter)]
    â†“
[Pydeck Visualization Renders]
    â†“
[Display: Interactive 3D Map + Risk Statistics]
```

### 3.3 Historical Analysis Data Flow

```
[User Opens Historical Event Analyzer Page]
    â†“
[Load 5 Models from Cache]
    â†“
[User Selects City + Date (date picker with 5-day delay constraint)]
    â†“
[Retrieve City Profile (lat, lon, baseline risk factors)]
    â†“
[Call Open-Meteo Archive API (lat, lon, selected_date)]
    â†“ (returns historical daily rainfall_mm for that date)
[Historical Rainfall Fetched (@st.cache_data)]
    â†“
[Map rainfall_mm to MonsoonIntensity [0-16]]
    â†“
[Construct Feature Vector (1 row Ã— 20 features)]
    â†“
[User Selects Model]
    â†“
[Model Predicts Flood Probability]
    â†“
[Risk Classification Logic]
    â”œâ”€â†’ prob < 0.3 â†’ LOW RISK
    â”œâ”€â†’ 0.3 â‰¤ prob < 0.7 â†’ MODERATE RISK
    â””â”€â†’ prob â‰¥ 0.7 â†’ HIGH RISK
    â†“
[Display: Rainfall (mm) + Flood Probability + Risk Conclusion]
```

### 3.4 Interactive Calculator Data Flow

```
[User Opens Risk Calculator Page]
    â†“
[Load 5 Models from Cache]
    â†“
[Display 20 Slider Inputs (Sidebar)]
    â”œâ”€â†’ MonsoonIntensity [0-16]
    â”œâ”€â†’ TopographyDrainage [0-20]
    â”œâ”€â†’ RiverManagement [0-20]
    â”œâ”€â†’ ... (17 more features)
    â””â”€â†’ PoliticalFactors [0-20]
    â†“
[User Adjusts Sliders (Real-time)]
    â†“
[Construct Feature Vector from Slider Values]
    â†“
[User Selects Model (Ensemble or Single)]
    â†“
[Model Predicts Flood Probability]
    â†“
[Display: Probability + Risk Gauge]
    â†“
[SHAP Force Plot Generation]
    â”œâ”€â†’ Load TreeExplainer for selected model
    â”œâ”€â†’ Compute SHAP values for feature vector
    â””â”€â†’ Generate force plot (red=increase risk, blue=decrease risk)
    â†“
[Display: Explainability Visualization]
    â†“
[Optional: Live Weather Helper]
    â””â”€â†’ Geocode user location â†’ Fetch current weather â†’ Auto-fill MonsoonIntensity
```

### 3.5 Model Performance Dashboard Data Flow

```
[User Opens Model Performance Page]
    â†“
[Load 5 Models from Cache]
    â†“
[Load Test Dataset (10,000 samples)]
    â†“
[Compute Predictions for Each Model]
    â”œâ”€â†’ LightGBM predictions
    â”œâ”€â†’ Random Forest predictions
    â”œâ”€â†’ XGBoost predictions
    â”œâ”€â†’ SVR predictions
    â””â”€â†’ KNN predictions
    â†“
[Calculate Metrics (RMSE, RÂ²) per Model]
    â†“
[Display: Performance Comparison Table]
    â†“
[User Selects Model for SHAP Analysis]
    â†“
[Initialize TreeExplainer with Selected Model]
    â†“
[Compute Global SHAP Values (sample of test set)]
    â†“
[Generate SHAP Summary Plot (bar chart)]
    â”œâ”€â†’ Feature names on Y-axis
    â”œâ”€â†’ Mean |SHAP value| on X-axis
    â””â”€â†’ Ranked by importance
    â†“
[Display: Global Feature Importance Visualization]
```

---

## 4. SEQUENCE DIAGRAMS (Textual Descriptions)

### 4.1 Live Forecast Prediction Sequence

```
Actor: User
System Components: Streamlit UI, Model Manager, Feature Engineer, Open-Meteo API, Pydeck

1. User â†’ Streamlit UI: Open homepage
2. Streamlit UI â†’ Model Manager: Load 5 models (@st.cache_resource)
3. Model Manager â†’ Streamlit UI: Return 5 loaded models
4. Streamlit UI â†’ User: Display city dropdown (32 cities)
5. User â†’ Streamlit UI: Select "Mumbai"
6. Streamlit UI â†’ Feature Engineer: Retrieve Mumbai profile (lat=19.0760, lon=72.8777)
7. Feature Engineer â†’ Open-Meteo API: GET /forecast?lat=19.0760&lon=72.8777&daily=precipitation_sum
8. Open-Meteo API â†’ Feature Engineer: Return {"precipitation_sum": [45.2]} (tomorrow)
9. Feature Engineer â†’ Feature Engineer: Map 45.2mm â†’ MonsoonIntensity=12
10. Feature Engineer â†’ Feature Engineer: Generate 100-point grid (Â±0.05Â° lat/lon variation)
11. Feature Engineer â†’ Model Manager: Feature matrix (100Ã—20)
12. User â†’ Streamlit UI: Select "Ensemble" mode
13. Model Manager â†’ Model Manager: Predict with all 5 models, average results
14. Model Manager â†’ Streamlit UI: Return 100 probabilities [0.62, 0.58, ..., 0.71]
15. Streamlit UI â†’ Pydeck: Render HeatmapLayer with probabilities
16. Pydeck â†’ User: Display interactive 3D heatmap
17. Streamlit UI â†’ User: Show statistics (Mean: 0.65, Max: 0.78, Min: 0.52)
```

### 4.2 Historical Analysis Sequence

```
Actor: User
System Components: Streamlit UI, Model Manager, Feature Engineer, Archive API

1. User â†’ Streamlit UI: Navigate to "Historical Event Analyzer"
2. Streamlit UI â†’ Model Manager: Load 5 models
3. Streamlit UI â†’ User: Display city dropdown + date picker
4. User â†’ Streamlit UI: Select "Chennai" + Date "2015-11-30"
5. Streamlit UI â†’ Feature Engineer: Retrieve Chennai profile (lat=13.0827, lon=80.2707)
6. Feature Engineer â†’ Archive API: GET /archive?lat=13.0827&lon=80.2707&start_date=2015-11-30&end_date=2015-11-30
7. Archive API â†’ Feature Engineer: Return {"precipitation_sum": [286.0]} (historical rainfall)
8. Feature Engineer â†’ Feature Engineer: Map 286.0mm â†’ MonsoonIntensity=16 (max)
9. Feature Engineer â†’ Model Manager: Feature vector (1Ã—20) with Chennai baseline + intensity=16
10. User â†’ Streamlit UI: Select "XGBoost" model
11. Model Manager â†’ Model Manager: XGBoost.predict(feature_vector)
12. Model Manager â†’ Streamlit UI: Return probability = 0.89
13. Streamlit UI â†’ Streamlit UI: Classify 0.89 â†’ HIGH RISK
14. Streamlit UI â†’ User: Display "Rainfall: 286.0mm | Probability: 0.89 | HIGH RISK âš ï¸"
```

### 4.3 SHAP Explanation Sequence

```
Actor: User
System Components: Streamlit UI, Model Manager, SHAP Engine, Matplotlib

1. User â†’ Streamlit UI: Navigate to "Risk Calculator"
2. Streamlit UI â†’ Model Manager: Load 5 models
3. Streamlit UI â†’ User: Display 20 sliders
4. User â†’ Streamlit UI: Adjust sliders (e.g., MonsoonIntensity=14, Deforestation=18)
5. Streamlit UI â†’ Feature Engineer: Construct feature vector from slider values
6. User â†’ Streamlit UI: Select "LightGBM" model
7. Model Manager â†’ Model Manager: LightGBM.predict(feature_vector)
8. Model Manager â†’ Streamlit UI: Return probability = 0.73
9. Streamlit UI â†’ User: Display "Flood Probability: 73%"
10. User â†’ Streamlit UI: Request SHAP explanation (auto-triggered)
11. Streamlit UI â†’ SHAP Engine: Initialize TreeExplainer(lgbm_model)
12. SHAP Engine â†’ SHAP Engine: Compute SHAP values for feature_vector
13. SHAP Engine â†’ SHAP Engine: shap_values = [0.12, -0.05, 0.18, ...] (20 values)
14. SHAP Engine â†’ Matplotlib: Generate force plot
    â”œâ”€â†’ Base value: 0.50 (global mean)
    â”œâ”€â†’ Red arrows: positive SHAP (increase risk) - MonsoonIntensity(+0.12), Deforestation(+0.18)
    â””â”€â†’ Blue arrows: negative SHAP (decrease risk) - DrainageSystems(-0.05)
15. Matplotlib â†’ Streamlit UI: Return force plot image
16. Streamlit UI â†’ User: Display explainability visualization
```

---

## 5. COMPONENT INTERACTION MATRIX

### 5.1 Component Dependencies

```
Component A â†’ Component B (Dependency Relationship)

Streamlit UI â†’ Model Manager (loads models, requests predictions)
Streamlit UI â†’ Feature Engineer (feature construction, preprocessing)
Streamlit UI â†’ SHAP Engine (explainability requests)
Streamlit UI â†’ Pydeck (visualization rendering)
Streamlit UI â†’ Open-Meteo APIs (weather data fetching)

Model Manager â†’ File System (model loading from .pkl files)
Model Manager â†’ feature_columns.json (feature alignment)
Model Manager â†’ SHAP Engine (provides model for TreeExplainer)

Feature Engineer â†’ Open-Meteo Forecast API (live rainfall data)
Feature Engineer â†’ Open-Meteo Archive API (historical rainfall data)
Feature Engineer â†’ City Profiles (baseline risk factors)

SHAP Engine â†’ Model Manager (requires loaded model)
SHAP Engine â†’ Matplotlib (visualization generation)

Training Pipeline â†’ flood.csv (dataset loading)
Training Pipeline â†’ File System (model saving)
Training Pipeline â†’ feature_columns.json (feature schema saving)

Cache Layer â†’ All API Calls (caching responses)
Cache Layer â†’ Model Loading (caching loaded models)
```

### 5.2 Data Exchange Formats

```
Component A â†â†’ Component B: Data Format

Streamlit UI â†â†’ Model Manager: 
    â†’ Feature matrix (numpy array: NÃ—20)
    â† Predictions (numpy array: NÃ—1)

Streamlit UI â†â†’ Open-Meteo APIs:
    â†’ HTTP GET request (lat, lon, date parameters)
    â† JSON response {"precipitation_sum": [float]}

Model Manager â†â†’ File System:
    â†’ joblib.load() call
    â† Scikit-learn model object (LGBMRegressor, etc.)

Feature Engineer â†â†’ City Profiles:
    â†’ City name (string)
    â† Dictionary {lat, lon, MonsoonIntensity, TopographyDrainage, ...}

SHAP Engine â†â†’ Model Manager:
    â†’ Model object + feature matrix
    â† SHAP values (numpy array: NÃ—20)

Training Pipeline â†â†’ flood.csv:
    â†’ pandas.read_csv() call
    â† DataFrame (50,001 rows Ã— 21 columns)
```

---

## 6. DEPLOYMENT ARCHITECTURE

### 6.1 Current Deployment (Local)

```
User's Machine
â”œâ”€â”€ Python 3.12 Runtime
â”œâ”€â”€ Streamlit Server (localhost:8501)
â”œâ”€â”€ Local File System
â”‚   â”œâ”€â”€ app.py + pages/
â”‚   â”œâ”€â”€ train_models.py
â”‚   â”œâ”€â”€ flood.csv
â”‚   â”œâ”€â”€ 5 Ã— .pkl model files
â”‚   â””â”€â”€ feature_columns.json
â””â”€â”€ Internet Connection (for Open-Meteo APIs)
```

### 6.2 Potential Cloud Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER BROWSER                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTPS
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            LOAD BALANCER / CDN                          â”‚
â”‚         (e.g., Cloudflare, AWS CloudFront)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          WEB SERVER (Streamlit Cloud / EC2)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Streamlit Application Container                â”‚   â”‚
â”‚  â”‚  - app.py + pages/                              â”‚   â”‚
â”‚  â”‚  - Python 3.12 environment                      â”‚   â”‚
â”‚  â”‚  - Dependencies (requirements.txt)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚              â”‚
                  â†“              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OBJECT STORAGE     â”‚  â”‚  EXTERNAL APIS       â”‚
    â”‚  (AWS S3 / Azure)   â”‚  â”‚  - Open-Meteo        â”‚
    â”‚  - Models (.pkl)    â”‚  â”‚  - Geocoding         â”‚
    â”‚  - flood.csv        â”‚  â”‚                      â”‚
    â”‚  - feature_columns  â”‚  â”‚                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   CACHE LAYER           â”‚
    â”‚   (Redis / Memcached)   â”‚
    â”‚   - API responses       â”‚
    â”‚   - Model predictions   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Deployment Options:**
1. **Streamlit Cloud:** Direct GitHub integration, free tier available
2. **AWS EC2 + S3:** Full control, scalable compute
3. **Google Cloud Run:** Containerized deployment, auto-scaling
4. **Azure App Service:** Managed PaaS, easy deployment
5. **Heroku:** Quick deployment, limited free tier

---

## 7. SECURITY & PERFORMANCE CONSIDERATIONS

### 7.1 Security Architecture

```
Security Layer: API Rate Limiting
â”œâ”€â”€ Open-Meteo API: Respect rate limits (10,000 requests/day free tier)
â”œâ”€â”€ Implement retry logic with exponential backoff
â””â”€â”€ requests-cache to reduce redundant API calls

Security Layer: Input Validation
â”œâ”€â”€ Feature value range validation (0-16, 0-20 scales)
â”œâ”€â”€ Date picker constraints (1940 to today-5days)
â”œâ”€â”€ City selection from predefined list (no arbitrary input)
â””â”€â”€ Model selection from predefined options

Security Layer: Data Privacy
â”œâ”€â”€ No user personal data collected
â”œâ”€â”€ No authentication/authorization required (public tool)
â””â”€â”€ No storage of user predictions (ephemeral sessions)

Security Layer: Model Integrity
â”œâ”€â”€ Models serialized with joblib (trusted library)
â”œâ”€â”€ Checksum validation on model loading (future enhancement)
â””â”€â”€ Read-only model files (no runtime modification)
```

### 7.2 Performance Optimization

```
Performance Layer: Caching Strategy
â”œâ”€â”€ @st.cache_resource for model loading
â”‚   â””â”€â”€ Load once, persist across sessions
â”œâ”€â”€ @st.cache_data for API responses
â”‚   â””â”€â”€ TTL-based expiration (1-hour for forecasts)
â”œâ”€â”€ requests-cache for HTTP responses
â”‚   â””â”€â”€ SQLite backend, configurable expiration
â””â”€â”€ Browser-side caching (Streamlit default)

Performance Layer: Lazy Loading
â”œâ”€â”€ Models loaded on-demand per page
â”œâ”€â”€ SHAP computations triggered only when requested
â””â”€â”€ Pydeck visualizations rendered incrementally

Performance Layer: Model Compression
â”œâ”€â”€ joblib compress=9 for .pkl files
â”œâ”€â”€ Reduced Random Forest trees (50 vs. default 100)
â””â”€â”€ Optimized XGBoost tree_method='hist'

Performance Layer: Batch Predictions
â”œâ”€â”€ Grid-based predictions (100 points) in single model call
â”œâ”€â”€ Vectorized numpy operations
â””â”€â”€ Avoid Python loops for feature engineering
```

---

## 8. ERROR HANDLING & RESILIENCE

### 8.1 Error Handling Flow

```
Error Type: API Failure (Open-Meteo unreachable)
â”œâ”€â†’ Catch requests.exceptions.RequestException
â”œâ”€â†’ Retry with exponential backoff (3 attempts)
â”œâ”€â†’ If all retries fail:
â”‚   â”œâ”€â†’ Use default/historical rainfall value
â”‚   â””â”€â†’ Display warning message to user
â””â”€â†’ Log error for monitoring

Error Type: Model Loading Failure
â”œâ”€â†’ Catch FileNotFoundError / pickle.UnpicklingError
â”œâ”€â†’ Display error message: "Model file corrupted or missing"
â”œâ”€â†’ Suggest retraining: "Run train_models.py"
â””â”€â†’ Graceful degradation: Disable affected page

Error Type: Invalid Feature Values
â”œâ”€â†’ Validate input ranges before prediction
â”œâ”€â†’ Clip values to valid ranges (e.g., [0, 16])
â”œâ”€â†’ Display warning: "Value adjusted to valid range"
â””â”€â†’ Proceed with corrected values

Error Type: SHAP Computation Failure
â”œâ”€â†’ Catch exceptions during TreeExplainer.shap_values()
â”œâ”€â†’ Display message: "Explainability unavailable for this model"
â”œâ”€â†’ Continue showing prediction without SHAP plot
â””â”€â†’ Log error (model compatibility issue)

Error Type: Pydeck Rendering Failure
â”œâ”€â†’ Catch JavaScript/WebGL errors
â”œâ”€â†’ Fallback to tabular prediction display
â”œâ”€â†’ Display message: "Map visualization unavailable"
â””â”€â†’ Suggest browser update or WebGL enablement
```

### 8.2 Resilience Strategies

```
Strategy: Graceful Degradation
â”œâ”€â”€ If XGBoost fails â†’ Use LightGBM as fallback
â”œâ”€â”€ If ensemble fails â†’ Use single best model (XGBoost)
â”œâ”€â”€ If live weather fails â†’ Use historical average
â””â”€â”€ If visualization fails â†’ Show text-based results

Strategy: Data Validation
â”œâ”€â”€ Schema validation for feature_columns.json
â”œâ”€â”€ Model compatibility checks (sklearn version)
â”œâ”€â”€ API response validation (expected JSON structure)
â””â”€â”€ User input sanitization (slider constraints)

Strategy: Monitoring & Logging
â”œâ”€â”€ Log model loading times (performance monitoring)
â”œâ”€â”€ Log API response times (detect degradation)
â”œâ”€â”€ Log prediction latencies (user experience tracking)
â””â”€â”€ Log error frequencies (identify failure patterns)
```

---

## 9. SCALABILITY CONSIDERATIONS

### 9.1 Horizontal Scaling

```
Current Architecture: Single-instance Streamlit
â””â”€â”€ Limitation: ~1000 concurrent users

Scaled Architecture: Multi-instance Deployment
â”œâ”€â”€ Load Balancer distributes traffic across N Streamlit instances
â”œâ”€â”€ Shared model storage (S3/Azure Blob)
â”œâ”€â”€ Distributed cache (Redis Cluster)
â””â”€â”€ Supports 10,000+ concurrent users

Implementation:
1. Containerize application (Docker)
2. Deploy to Kubernetes cluster or serverless platform
3. Configure auto-scaling (CPU/memory thresholds)
4. Implement session affinity (sticky sessions)
```

### 9.2 Vertical Scaling

```
CPU Optimization:
â”œâ”€â”€ Current: Single-threaded prediction
â”œâ”€â”€ Scaled: Multi-threaded batch predictions (joblib n_jobs=-1)
â””â”€â”€ Impact: 2-4Ã— speedup for large grids

Memory Optimization:
â”œâ”€â”€ Current: All models loaded simultaneously (~500MB RAM)
â”œâ”€â”€ Scaled: Lazy model loading per request
â””â”€â”€ Impact: Reduce baseline memory by 80%

GPU Acceleration (Future):
â”œâ”€â”€ XGBoost GPU training (tree_method='gpu_hist')
â”œâ”€â”€ TensorFlow/PyTorch model conversion for inference
â””â”€â”€ Impact: 10-100Ã— speedup for training and inference
```

---

## 10. FUTURE ENHANCEMENTS

### 10.1 Planned Features

```
Enhancement: Real-time Alerting System
â”œâ”€â”€ User subscription to specific cities
â”œâ”€â”€ Email/SMS notifications when risk > threshold
â”œâ”€â”€ Integration with SMTP server or Twilio API
â””â”€â”€ Webhook support for third-party integrations

Enhancement: Historical Validation Dashboard
â”œâ”€â”€ Compare model predictions vs. actual flood events (if available)
â”œâ”€â”€ Precision/Recall metrics over time
â”œâ”€â”€ Interactive timeline visualization
â””â”€â”€ Model retraining trigger based on drift detection

Enhancement: Multi-region Support
â”œâ”€â”€ Expand beyond India (Southeast Asia, Americas, Europe)
â”œâ”€â”€ Localized weather API endpoints
â”œâ”€â”€ Region-specific risk factor weights
â””â”€â”€ Multi-language UI support

Enhancement: Advanced Ensemble Techniques
â”œâ”€â”€ Weighted averaging (based on model confidence)
â”œâ”€â”€ Stacking meta-learner (train combiner model)
â”œâ”€â”€ Dynamic model selection (context-dependent)
â””â”€â”€ Uncertainty quantification (prediction intervals)

Enhancement: Mobile Application
â”œâ”€â”€ React Native / Flutter mobile app
â”œâ”€â”€ Offline prediction capability (cached models)
â”œâ”€â”€ GPS-based automatic location detection
â””â”€â”€ Push notifications for local alerts
```

### 10.2 Technical Debt & Improvements

```
Code Quality:
â”œâ”€â”€ Add comprehensive unit tests (pytest)
â”œâ”€â”€ Implement integration tests (API mocking)
â”œâ”€â”€ Add type hints (mypy validation)
â””â”€â”€ Refactor duplicated code (DRY principle)

Documentation:
â”œâ”€â”€ Add inline docstrings (Google/NumPy style)
â”œâ”€â”€ Generate API documentation (Sphinx)
â”œâ”€â”€ Create user manual (README expansion)
â””â”€â”€ Video tutorials for deployment

Infrastructure:
â”œâ”€â”€ CI/CD pipeline (GitHub Actions)
â”œâ”€â”€ Automated model retraining (scheduled jobs)
â”œâ”€â”€ A/B testing framework (model version comparison)
â””â”€â”€ Monitoring dashboard (Grafana/Prometheus)
```

---

## 11. VISUAL DIAGRAM RECOMMENDATIONS

### 11.1 Suggested Diagrams to Create

**1. System Context Diagram**
- Actors: End Users, Administrators, External APIs
- System Boundary: Project AQUA Application
- External Systems: Open-Meteo API, GitHub Repository
- Purpose: High-level overview of system interactions

**2. Container Diagram (C4 Model)**
- Containers: Streamlit Web App, Model Storage, Dataset Storage, Cache
- Technology labels: Python 3.12, Streamlit, joblib, requests-cache
- Purpose: Show major deployable units and technologies

**3. Component Diagram**
- Within "Streamlit Web App" container
- Components: Homepage, Historical Analyzer, Calculator, Performance Dashboard, Model Manager, SHAP Engine
- Purpose: Internal structure of main application

**4. Sequence Diagrams** (Use textual descriptions from Section 4)
- Live Forecast Flow
- Historical Analysis Flow
- SHAP Explanation Flow

**5. Deployment Diagram**
- Show current local deployment
- Show proposed cloud deployment architecture
- Include network boundaries, firewalls, load balancers

**6. Data Flow Diagram (DFD)**
- Training Pipeline Flow
- Live Prediction Flow
- Show data transformations at each stage

**7. Entity-Relationship Diagram** (if applicable)
- flood.csv structure
- feature_columns.json schema
- City profiles structure

**8. State Machine Diagram**
- User session states: Landing â†’ City Selection â†’ Prediction â†’ Explainability
- Model states: Unloaded â†’ Loading â†’ Loaded â†’ Predicting

### 11.2 Diagramming Tools Recommendations

- **Draw.io (diagrams.net):** Free, web-based, extensive shape libraries
- **Lucidchart:** Professional, collaborative, templates for UML/C4
- **PlantUML:** Text-based, version-controllable, integrates with documentation
- **Mermaid:** Markdown-integrated, GitHub-rendered, simple syntax
- **Microsoft Visio:** Professional, comprehensive, Windows-native
- **Excalidraw:** Hand-drawn style, lightweight, open-source

---

## 12. APPENDIX: KEY DESIGN PATTERNS USED

### 12.1 Architectural Patterns

```
Pattern: Three-Tier Architecture
â”œâ”€â”€ Separation of concerns: Presentation, Business Logic, Data
â”œâ”€â”€ Benefit: Maintainability, independent scaling
â””â”€â”€ Implementation: Streamlit (UI) | Python modules (logic) | Files/APIs (data)

Pattern: Model-View-Controller (MVC)
â”œâ”€â”€ Model: ML models, data structures (City profiles)
â”œâ”€â”€ View: Streamlit UI components (pages, visualizations)
â””â”€â”€ Controller: Feature engineering, prediction routing

Pattern: Facade Pattern
â”œâ”€â”€ Model Manager provides simple interface to 5 complex models
â”œâ”€â”€ Feature Engineer abstracts preprocessing complexity
â””â”€â”€ SHAP Engine hides explainability computation details

Pattern: Strategy Pattern
â”œâ”€â”€ Prediction strategy: Ensemble vs. Single model
â”œâ”€â”€ Visualization strategy: Heatmap vs. Hexagon vs. Scatter
â””â”€â”€ Explainability strategy: Global vs. Local SHAP
```

### 12.2 Design Principles Applied

```
SOLID Principles:
â”œâ”€â”€ Single Responsibility: Each page handles one concern
â”œâ”€â”€ Open/Closed: Add new models without modifying core logic
â”œâ”€â”€ Liskov Substitution: All models implement same predict() interface
â”œâ”€â”€ Interface Segregation: Separate interfaces for classifiers vs. regressors
â””â”€â”€ Dependency Inversion: Depend on abstractions (model interface) not concretions

DRY (Don't Repeat Yourself):
â”œâ”€â”€ City profiles defined once, used across all pages
â”œâ”€â”€ Model loading logic centralized in single function
â””â”€â”€ Feature engineering utilities shared across modules

KISS (Keep It Simple, Stupid):
â”œâ”€â”€ Straightforward linear prediction pipeline
â”œâ”€â”€ Minimal external dependencies
â””â”€â”€ Clear, readable code over clever optimizations
```

---

**End of System Design Specification**

This document provides all necessary textual information to create comprehensive visual system design diagrams. Use the component descriptions, data flows, and interaction patterns as a blueprint for your visual designs.

**Recommended Next Steps:**
1. Create high-level System Context Diagram
2. Design detailed Component Diagram
3. Document data flows with DFD
4. Visualize deployment architecture
5. Add sequence diagrams for key user flows

For questions or clarifications on any section, refer back to the PROJECT_STATUS_REPORT.md for implementation details.
